{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import binascii\n",
    "import os\n",
    "import urllib3\n",
    "import certifi\n",
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# Чтение из файла search_url_list.txt поисковых запросов по сайту\n",
    "# ----------------------------------------------------------------------\n",
    "def get_search_url(search_url_file = 'search_url_list.txt'):\n",
    "\n",
    "    search_url_list = []\n",
    "\n",
    "    with open(search_url_file, 'r') as f:\n",
    "        urls = f.readlines()\n",
    "\n",
    "    for current_string in urls:\n",
    "        if current_string[0:1] == '#' or current_string[0:1] == '\\n':\n",
    "            continue\n",
    "        search_url_list.append(current_string.rstrip())\n",
    "\n",
    "    return search_url_list\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def get_vacancies(url_list, vacancies, log_file_name='vacancy_log.txt'):\n",
    "\n",
    "    date_from = (date.today() - timedelta(hours=24)).isoformat()\n",
    "    searches = []\n",
    "    new_vacancies = []\n",
    "\n",
    "    with open(log_file_name, 'a') as logfile:\n",
    "\n",
    "        for url in url_list:\n",
    "            for page in range(50):\n",
    "                try:\n",
    "                    # searches.append(requests.get(url + '&page={}&per_page=100&date_from={}'.format(page, date_from)).json())\n",
    "                    searches.append(requests.get(url).json())\n",
    "                except Exception as ex_err:\n",
    "                    logfile.write('==> ERROR: {} W= Read Vacansies ===> {}'.format(date.today().isoformat(), ex_err) + '\\n')\n",
    "\n",
    "        try:\n",
    "            for items in searches:\n",
    "                for j in items['items']:\n",
    "                    if j['id'] not in vacancies:\n",
    "                        vacancies.append(j['id'])\n",
    "                        new_vacancies.append(j['id'])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return new_vacancies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# def respond_to_vacancies(vacancies, resume_id, message='', log_file_name='vacancy_log.txt'):\n",
    "#\n",
    "#     http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())\n",
    "#\n",
    "#     with open(log_file_name, 'a') as logfile:\n",
    "#\n",
    "#         for vacancy_id in vacancies:\n",
    "#             try:\n",
    "#\n",
    "#                 body, content_type = encode_multipart_formdata({'vacancy_id': '{}'.format(vacancy_id),\n",
    "#                                      'resume_id' : '{}'.format(resume_id),\n",
    "#                                      'message'   : '{}'.format(message)})\n",
    "#\n",
    "#                 r = http.request('POST', 'https://api.hh.ru/negotiations',\n",
    "#                                         headers = {'Authorization' : 'Bearer {}'.format(user_token_params['access_token']),\n",
    "#                                                   'Accept'        : '*/*',\n",
    "#                                                   'User-Agent'    : 'CIO_jbSearch (ssv.ruby@gmail.com)',\n",
    "#                                                   'Content-Type'  : '{}'.format(content_type)},\n",
    "#                                         body =  '{}'.format(body)\n",
    "#                                       )\n",
    "#\n",
    "#                 result = 'Vacancy_id: {}, Date: {}, Status: {}, Reason: {}, Response_link: {}'.format(vacancy_id, r.getheader('Date'),\n",
    "#                                                                                 r.status, r.reason,\n",
    "#                                                                                 'https://hh.ru/applicant{}'.format(r.getheader('Location')))\n",
    "#                 logfile.write('{} == Respond Vacansies ===> {}'.format(date.today().isoformat(), result) + '\\n')\n",
    "#\n",
    "#             except Exception as ex_err:\n",
    "#                 logfile.write('{} W= Respond ERROR ===> {}'.format(date.today().isoformat(), ex_err) + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#  Список просмотренных вакансий (Глобальная переменная)\n",
    "# ----------------------------------------------------------------------\n",
    "vacancies = []                                       #  Список просмотренных вакансий (Глобальная переменная)\n",
    "resume_id = '6e1019f2ff040603530039ed1f4b59356a4b71' # IT Directot\n",
    "period    = 900                                      # 900 сек - период обращения к сайту"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Get authorisation params\n",
    "with open('user_token_params.json', 'r', encoding='utf-8') as f:\n",
    "    user_token_params = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "vacancies = []\n",
    "url_list = []\n",
    "# url_list.append('https://api.hh.ru/vacancies?&text=%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%81%D1%82+Python')\n",
    "# url_list.append('https://api.hh.ru/vacancies?text=%D0%9F%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%81%D1%82+data+science')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "new_vacancies = get_vacancies(url_list, vacancies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_vacancies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "53"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_vacancies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
